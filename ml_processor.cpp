/*
 * ml_processor.cpp - Implementa√ß√£o corrigida e simplificada
 */

#include "ml_processor.h"
#include "tflite_config.h"


MLProcessor::MLProcessor() : 
#if TFLITE_AVAILABLE
    interpreter(nullptr),
    input_tensor(nullptr),
    output_tensor(nullptr),
#endif
    last_confidence(0.0f),
    ml_initialized(false) {
}

bool MLProcessor::begin() {
    Serial.println("üß† Inicializando ML Processor...");
    
#if TFLITE_AVAILABLE
    try {
        // Verificar se o modelo existe
        if (g_model_data_len < 32) {
            Serial.println("‚ö†Ô∏è Modelo muito pequeno - usando simula√ß√£o");
            ml_initialized = false;
            return true; // Permitir modo simula√ß√£o
        }

        // Verificar magic number do TensorFlow Lite
        const char* magic = reinterpret_cast<const char*>(g_model_data);
        if (strncmp(magic + 4, "TFL3", 4) != 0) {
            Serial.println("‚ö†Ô∏è Magic number inv√°lido - usando simula√ß√£o");
            ml_initialized = false;
            return true;
        }

        // Criar modelo
        const tflite::Model* model = tflite::GetModel(g_model_data);
        if (model->version() != TFLITE_SCHEMA_VERSION) {
            Serial.printf("‚ö†Ô∏è Vers√£o do modelo (%d) incompat√≠vel com schema (%d)\n", 
                         model->version(), TFLITE_SCHEMA_VERSION);
            ml_initialized = false;
            return true;
        }

        // Resolver opera√ß√µes
        static tflite::AllOpsResolver resolver;

        // Criar interpretador
        static tflite::MicroInterpreter static_interpreter(
            model, resolver, tensor_arena, kTensorArenaSize);
        
        interpreter = &static_interpreter;

        // Alocar tensores
        TfLiteStatus allocate_status = interpreter->AllocateTensors();
        if (allocate_status != kTfLiteOk) {
            Serial.println("‚ùå Falha ao alocar tensores");
            ml_initialized = false;
            return true; // Usar simula√ß√£o
        }

        // Obter tensores I/O
        input_tensor = interpreter->input(0);
        output_tensor = interpreter->output(0);

        if (!input_tensor || !output_tensor) {
            Serial.println("‚ùå Tensores I/O nulos");
            ml_initialized = false;
            return true;
        }

        // Verificar dimens√µes
        if (input_tensor->type != kTfLiteFloat32) {
            Serial.println("‚ùå Tipo de entrada inv√°lido");
            ml_initialized = false;
            return true;
        }

        ml_initialized = true;
        Serial.printf("‚úÖ TensorFlow Lite inicializado!\n");
        Serial.printf("   üì• Input: [%d] float32 (%d bytes)\n", 
                     input_tensor->dims->data[1], input_tensor->bytes);
        Serial.printf("   üì§ Output: [%d] float32 (%d bytes)\n", 
                     output_tensor->dims->data[1], output_tensor->bytes);
        Serial.printf("   üíæ Arena usada: %d KB\n", 
                     interpreter->arena_used_bytes() / 1024);
        
        return true;

    } catch (const std::exception& e) {
        Serial.printf("‚ùå Exce√ß√£o TF Lite: %s\n", e.what());
        ml_initialized = false;
        return true;
    } catch (...) {
        Serial.println("‚ùå Exce√ß√£o desconhecida no TF Lite");
        ml_initialized = false;
        return true;
    }
#else
    Serial.println("‚ö†Ô∏è TensorFlow Lite n√£o dispon√≠vel - modo simula√ß√£o");
    ml_initialized = false;
    return true;
#endif
}

int MLProcessor::predict(const float* input_data, size_t length) {
    if (!input_data || length == 0) {
        Serial.println("‚ùå Dados de entrada inv√°lidos");
        return -1;
    }

#if TFLITE_AVAILABLE
    if (ml_initialized && interpreter && input_tensor && output_tensor) {
        try {
            // Preparar entrada
            float* input_buffer = input_tensor->data.f;
            size_t input_size = input_tensor->bytes / sizeof(float);
            size_t copy_size = min(length, input_size);

            // Copiar e normalizar dados
            for (size_t i = 0; i < copy_size; i++) {
                input_buffer[i] = constrain(input_data[i], -1.0f, 1.0f);
            }

            // Preencher resto com zeros se necess√°rio
            for (size_t i = copy_size; i < input_size; i++) {
                input_buffer[i] = 0.0f;
            }

            // Executar infer√™ncia
            TfLiteStatus invoke_status = interpreter->Invoke();
            if (invoke_status != kTfLiteOk) {
                Serial.println("‚ùå Falha na infer√™ncia");
                simulate_prediction(int result, last_confidence);
                return result;
            }

            // Processar sa√≠da
            float* output_data = output_tensor->data.f;
            int output_size = output_tensor->bytes / sizeof(float);
            output_size = min(output_size, OUTPUT_CLASSES);

            // Encontrar classe com maior probabilidade
            int predicted_class = 0;
            float max_prob = output_data[0];

            for (int i = 1; i < output_size; i++) {
                if (output_data[i] > max_prob) {
                    max_prob = output_data[i];
                    predicted_class = i;
                }
            }

            // Aplicar softmax se necess√°rio (verificar se j√° est√° normalizado)
            float sum = 0.0f;
            for (int i = 0; i < output_size; i++) {
                sum += output_data[i];
            }

            if (sum > 1.1f || sum < 0.9f) {
                // Aplicar softmax
                float max_val = max_prob;
                sum = 0.0f;
                for (int i = 0; i < output_size; i++) {
                    output_data[i] = exp(output_data[i] - max_val);
                    sum += output_data[i];
                }
                for (int i = 0; i < output_size; i++) {
                    output_data[i] /= sum;
                }
                max_prob = output_data[predicted_class];
            }

            last_confidence = max_prob;
            return predicted_class;

        } catch (...) {
            Serial.println("‚ùå Exce√ß√£o durante infer√™ncia");
            simulate_prediction(int result, last_confidence);
            return result;
        }
    }
#endif

    // Fallback: simula√ß√£o
    int result;
    simulate_prediction(result, last_confidence);
    return result;
}

void MLProcessor::simulate_prediction(int& result, float& confidence) {
    // Simula√ß√£o baseada em energia do sinal de entrada
    static unsigned long last_sim = 0;
    static int last_result = 0;
    
    unsigned long now = millis();
    
    // Mudar resultado a cada 2-5 segundos
    if (now - last_sim > random(2000, 5000)) {
        last_result = random(0, OUTPUT_CLASSES);
        last_sim = now;
    }
    
    result = last_result;
    confidence = 0.65f + (random(0, 30) / 100.0f); // 65-95%
}

float MLProcessor::get_confidence() const {
    return last_confidence;
}

bool MLProcessor::is_available() const {
#if TFLITE_AVAILABLE
    return ml_initialized;
#else
    return false; // Simula√ß√£o n√£o conta como "dispon√≠vel"
#endif
}

void MLProcessor::print_model_info() const {
    Serial.println("\nüß† ML PROCESSOR INFO:");
    
#if TFLITE_AVAILABLE
    if (ml_initialized && interpreter) {
        Serial.printf("   ‚úÖ Status: Inicializado\n");
        Serial.printf("   üì• Input: %d bytes\n", input_tensor ? input_tensor->bytes : 0);
        Serial.printf("   üì§ Output: %d bytes\n", output_tensor ? output_tensor->bytes : 0);
        Serial.printf("   üíæ Arena: %d KB\n", interpreter->arena_used_bytes() / 1024);
        Serial.printf("   üéØ Classes: %d\n", OUTPUT_CLASSES);
    } else {
        Serial.println("   ‚ö†Ô∏è Status: Simula√ß√£o (TF Lite dispon√≠vel mas n√£o inicializado)");
    }
#else
    Serial.println("   ‚ö†Ô∏è Status: Simula√ß√£o (TF Lite n√£o dispon√≠vel)");
#endif
    
    Serial.printf("   üé≤ √öltima confian√ßa: %.1f%%\n", last_confidence * 100);
}
